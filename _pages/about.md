---
permalink: /
title: "Li Yang(杨立)"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

中国科学院软件研究所正高级工程师，硕导

研究领域：智能化软件开发方法及质量保障,精准计算

精准计算作为一种应对现实世界复杂问题的方法，着眼于人工智能、大数据与应用软件的融合，具有研究领域融入能力、可迭代性、逐渐精化和依概率收敛等特征，旨在解决大数据时代面临的不确定性和复杂性，通过建立可靠的智能模型和算法，使得计算结果更为准确、可控，从而为决策者提供可信的依据。

[“精准计算与大数据”专栏征稿启事](https://hbkx.cbpt.cnki.net/portal/journal/portal/client/news/551192a9c2b6dd04c0b574a0363755a9)

2025年05月  "Towards Practical Defect-Focused Automated Code Review" was accepted by ICML 2025 spotlight
<br />
2025年03月  "Smart-LLaMA-DPO: Reinforced Large Language Model for Explainable Smart Contract Vulnerability Detection" was accepted by ISSTA 2025
<br />
2025年03月  Served as ACL2025 Reviewer 
<br />
2024年11月  学术论文"一种索引结构优化的检索增强生成技术在保险领域的交互应用研究" 被 河北省科学院学报 录用  
2024年11月  学术论文"基于多模态知识的垂直行业领域精准计算实现方法研究" 被 河北省科学院学报 录用 

学术成果：基于精准计算的自动化代码审查方法LLaMA-Reviewer

现有的主流方法通过预训练模型技术来开展代码审查自动化研究，尽管取得了一些成功，但这些模型经常需要大量资源来从头开始进行预训练。相比之下，大型语言模型提供了一种可行且高效的替代方案，在补充特定领域的知识后，它们能在多个任务上同时提供具有卓越的功能。然而，它们在自动化代码审查任务的实际性能表现未被有效探明。
![image](https://github.com/user-attachments/assets/016b4842-defb-4662-9787-a78529c802fb)
为了弥补这一研究空白，我们提出了基于精准计算的自动化代码审查方法LLaMA-Reviewer，它利用流行的开源大语言模型-LLaMA来实现其在代码审查自动化的各项任务。该框架采用双阶段微调过程，如上图所示。首先使用以代码审查实际数据集对LLaMA进行指令微调，以提高模型理解代码审查任务和遵守任务指令的熟练程度。然后使用增强的 LLaMA 对代码审查过程中的每个子任务进行监督微调。这些子任务包括了1）必要性预测：检查差异代码块是否需要审查；2）代码评审意见生成：为给定的代码片段生成相关评审意见；3）代码修复：对现有代码进行细微调整或重新排序以提高其质量。同时，为了平衡参数效率和模型性能，我们采用了两种关键技术：1）零初始注意力前缀微调：保持基本模型的权重完整，同时将额外的K前缀标记集成到自注意力模型的最顶层L层中，并与原始标记连接在一起，允许使用新引入的键和值来计算多头注意力——在微调过程中，仅训练这些适应层。2）低秩自适应（Low-Rank Adaptation,简称LoRA）微调：LoRA 固定原始模型的权重，并将可训练的低秩矩阵集成到自注意力模型层以模拟权重调整。我们选取这两种参数高效微调方法，因为它们已经获得了广泛的接受和有希望的结果，尤其是在LLaMA系列模型上。这些方法基于参数高效微调的插件封装策略，提供了轻量级的特定于任务的插件。这些插件独立于基本模型的权重，可以在推理过程中无缝集成。

LLaMA-Reviewer的评估是在两个不同的、公开可用的数据集上进行的。实验证明，尽管使用最小版本的LLaMA（只有 6.7B 参数）以及少于1%的可训练参数，LLaMA-Reviewer已经可以匹配最先进代码审查模型的性能。此外，通过应用插件式模型，该方法显著降低了存储空间需求。我们的研究结果还表明，将输入表示与预训练期间使用的格式保持一致可以更好地利用大语言模型的能力。此外，指令微调的初始阶段可以提高任务性能并增强模型处理其他自然语言信息的能力。实验结果还表明，对于具有特定输入和输出格式的任务，具有适当秩的低秩自适应更为有效。相关成果发表在ISSRE 2023（CCF-B）上，目前已被引98次。
